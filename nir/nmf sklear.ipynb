{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "model.fit(X) \n",
    "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
    "  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,\n",
    "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.09783018,  0.30560234],\n",
       "       [ 2.13443044,  2.13171694]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001159934921600414"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reconstruction_err_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read MovieLens data set\n",
      "Algorithm: snmf - r\n",
      "Initialization: random_vcol\n",
      "Rank: 30\n",
      "Stats:\n",
      "            - iterations: 30\n",
      "            - Euclidean distance: 113885.398\n",
      "            - Sparseness basis: 0.145, mixture: 0.429\n",
      "RMSE: 1.686\n",
      "Read MovieLens data set\n",
      "Algorithm: snmf - r\n",
      "Initialization: random_vcol\n",
      "Rank: 30\n",
      "Stats:\n",
      "            - iterations: 30\n",
      "            - Euclidean distance: 113570.262\n",
      "            - Sparseness basis: 0.144, mixture: 0.475\n",
      "RMSE: 1.696\n"
     ]
    }
   ],
   "source": [
    "import nimfa.examples\n",
    "nimfa.examples.recommendations.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read MovieLens data set\n",
      "Algorithm: snmf - r\n",
      "Initialization: random_vcol\n",
      "Rank: 30\n",
      "Stats:\n",
      "            - iterations: 30\n",
      "            - Euclidean distance: 113908.611\n",
      "            - Sparseness basis: 0.144, mixture: 0.387\n",
      "fname C:/Anaconda2/Lib/site-packages/nimfa\\datasets\\MovieLens\\ua.test\n",
      "RMSE: 1.683\n",
      "k = 1\n",
      "1  is k and precision_at_k:  0.901378579003\n",
      "1  is k and ndcg_at_k:  0.901378579003\n",
      "k = 3\n",
      "3  is k and precision_at_k:  0.900318133616\n",
      "3  is k and ndcg_at_k:  0.900525512878\n",
      "k = 5\n",
      "5  is k and precision_at_k:  0.88525980912\n",
      "5  is k and ndcg_at_k:  0.892682403729\n",
      "k = 10\n",
      "10  is k and precision_at_k:  0.850053022269\n",
      "10  is k and ndcg_at_k:  0.947138361287\n",
      "Read MovieLens data set\n",
      "Algorithm: snmf - r\n",
      "Initialization: random_vcol\n",
      "Rank: 30\n",
      "Stats:\n",
      "            - iterations: 30\n",
      "            - Euclidean distance: 113556.436\n",
      "            - Sparseness basis: 0.144, mixture: 0.508\n",
      "fname C:/Anaconda2/Lib/site-packages/nimfa\\datasets\\MovieLens\\ub.test\n",
      "RMSE: 1.703\n",
      "k = 1\n",
      "1  is k and precision_at_k:  0.916224814422\n",
      "1  is k and ndcg_at_k:  0.916224814422\n",
      "k = 3\n",
      "3  is k and precision_at_k:  0.905620360551\n",
      "3  is k and ndcg_at_k:  0.908149291731\n",
      "k = 5\n",
      "5  is k and precision_at_k:  0.893531283139\n",
      "5  is k and ndcg_at_k:  0.900551296317\n",
      "k = 10\n",
      "10  is k and precision_at_k:  0.853022269353\n",
      "10  is k and ndcg_at_k:  0.95229179215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    ##############################################\n",
    "    Recommendations (``examples.recommendations``)\n",
    "    ##############################################\n",
    "    \n",
    "    In this examples of collaborative filtering we consider movie recommendation using common MovieLens data set. It \n",
    "    represents typical cold start problem. A recommender system compares the user's profile to reference\n",
    "    characteristics from the user's social environment. In the collaborative filtering approach, the recommender\n",
    "    system identify users who share the same preference with the active user and propose items which the like-minded\n",
    "    users favoured (and the active user has not yet seen).     \n",
    "    \n",
    "    We used the MovieLens 100k data set in this example. This data set consists of 100 000 ratings (1-5) from 943\n",
    "    users on 1682 movies. Each user has rated at least 20 movies. Simple demographic info for the users is included. \n",
    "    Factorization is performed on a split data set as provided by the collector of the data. The data is split into \n",
    "    two disjoint sets each consisting of training set and a test set with exactly 10 ratings per user. \n",
    "    \n",
    "    It is common that matrices in the field of recommendation systems are very sparse (ordinary user rates only a small\n",
    "    fraction of items from the large items' set), therefore ``scipy.sparse`` matrix formats are used in this example. \n",
    "    \n",
    "    The configuration of this example is SNMF/R factorization method using Random Vcol algorithm for initialization. \n",
    "    \n",
    "    .. note:: MovieLens movies' rating data set used in this example is not included in the `datasets` and need to be\n",
    "      downloaded. Download links are listed in the ``datasets``. Download compressed version of the MovieLens 100k. \n",
    "      To run the example, the extracted data set must exist in the ``MovieLens`` directory under ``datasets``. \n",
    "      \n",
    "    .. note:: No additional knowledge in terms of ratings' timestamps, information about items and their\n",
    "       genres or demographic information about users is used in this example. \n",
    "      \n",
    "    To run the example simply type::\n",
    "        \n",
    "        python recommendations.py\n",
    "        \n",
    "    or call the module's function::\n",
    "    \n",
    "        import nimfa.examples\n",
    "        nimfa.examples.recommendations.run()\n",
    "        \n",
    "    .. note:: This example uses ``matplotlib`` library for producing visual interpretation of the RMSE error measure. \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "from os.path import dirname, abspath\n",
    "from os.path import join\n",
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nimfa\n",
    "import metrics\n",
    "\n",
    "\n",
    "try:\n",
    "    import matplotlib.pylab as plb\n",
    "except ImportError as exc:\n",
    "    warn(\"Matplotlib must be installed to run Recommendations example.\")\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Run SNMF/R on the MovieLens data set.\n",
    "    \n",
    "    Factorization is run on `ua.base`, `ua.test` and `ub.base`, `ub.test` data set. This is MovieLens's data set split \n",
    "    of the data into training and test set. Both test data sets are disjoint and with exactly 10 ratings per user\n",
    "    in the test set. \n",
    "    \"\"\"\n",
    "    for data_set in ['ua', 'ub']:\n",
    "        V = read(data_set)\n",
    "        W, H = factorize(V)\n",
    "        rmse(W, H, data_set)\n",
    "\n",
    "\n",
    "def factorize(V):\n",
    "    \"\"\"\n",
    "    Perform SNMF/R factorization on the sparse MovieLens data matrix. \n",
    "    \n",
    "    Return basis and mixture matrices of the fitted factorization model. \n",
    "    \n",
    "    :param V: The MovieLens data matrix. \n",
    "    :type V: `numpy.matrix`\n",
    "    \"\"\"\n",
    "    snmf = nimfa.Snmf(V, seed=\"random_vcol\", rank=30, max_iter=30, version='r', eta=1.,\n",
    "                      beta=1e-4, i_conv=10, w_min_change=0)\n",
    "    print(\"Algorithm: %s\\nInitialization: %s\\nRank: %d\" % (snmf, snmf.seed, snmf.rank))\n",
    "    fit = snmf()\n",
    "    sparse_w, sparse_h = fit.fit.sparseness()\n",
    "    print(\"\"\"Stats:\n",
    "            - iterations: %d\n",
    "            - Euclidean distance: %5.3f\n",
    "            - Sparseness basis: %5.3f, mixture: %5.3f\"\"\" % (fit.fit.n_iter,\n",
    "                                                            fit.distance(metric='euclidean'),\n",
    "                                                            sparse_w, sparse_h))\n",
    "    return fit.basis(), fit.coef()\n",
    "\n",
    "\n",
    "def read(data_set):\n",
    "    \"\"\"\n",
    "    Read movies' ratings data from MovieLens data set. \n",
    "    \n",
    "    :param data_set: Name of the split data set to be read.\n",
    "    :type data_set: `str`\n",
    "    \"\"\"\n",
    "    print(\"Read MovieLens data set\")\n",
    "    fname = join(dirname('C:/Anaconda2/Lib/site-packages/nimfa/'), \"datasets\", \"MovieLens\", \"%s.base\" % data_set)\n",
    "    V = np.ones((943, 1682)) * 2.5\n",
    "    for line in open(fname):\n",
    "        u, i, r, _ = list(map(int, line.split()))\n",
    "        V[u - 1, i - 1] = r\n",
    "    return V\n",
    "\n",
    "\n",
    "def rmse(W, H, data_set):\n",
    "    \"\"\"\n",
    "    Compute the RMSE error rate on MovieLens data set.\n",
    "    \n",
    "    :param W: Basis matrix of the fitted factorization model.\n",
    "    :type W: `numpy.matrix`\n",
    "    :param H: Mixture matrix of the fitted factorization model.\n",
    "    :type H: `numpy.matrix`\n",
    "    :param data_set: Name of the split data set to be read. \n",
    "    :type data_set: `str`\n",
    "    \"\"\"\n",
    "    fname = join(dirname('C:/Anaconda2/Lib/site-packages/nimfa/'), \"datasets\", \"MovieLens\", \"%s.test\" % data_set)\n",
    "    rmse = []\n",
    "    print 'fname', fname\n",
    "    test = np.zeros((943, 1682)) \n",
    "    for line in open(fname):\n",
    "        u, i, r, _ = list(map(int, line.split()))\n",
    "        test[u-1][i-1] = r\n",
    "        sc = max(min((W[u - 1, :] * H[:, i - 1])[0, 0], 5), 1)\n",
    "        rmse.append((sc - r) ** 2)\n",
    "    print(\"RMSE: %5.3f\" % np.mean(rmse))\n",
    "    VV = np.asarray(np.dot(W,H))\n",
    "    for k in [1,3,5,10]:\n",
    "        print 'k =', k\n",
    "        counts = 0\n",
    "        pres = 0\n",
    "        ndcg = 0\n",
    "        for ii, user in enumerate(VV):\n",
    "            counts+=1\n",
    "            r = np.argsort(user)[::-1]\n",
    "            rr = []\n",
    "            for jj in (r):\n",
    "                if test[ii][jj] != 0:\n",
    "                    rr.append(1 if VV[ii][jj]-0.49 < test[ii][jj] else 0)\n",
    "            #print rr\n",
    "            pres += metrics.precision_at_k(rr,k)\n",
    "            ndcg += metrics.ndcg_at_k(rr,k)\n",
    "        print k,\" is k and precision_at_k: \", pres*1.0/counts\n",
    "        print k,\" is k and ndcg_at_k: \", ndcg*1.0/counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Run the Recommendations example.\"\"\"\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "user = [ 4.74850767,  2.82699823,  3.08403436]\n",
    "r= np.argsort(user)[::-1]\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
